% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode
%!TeX spellcheck = en-US,en-DE

\documentclass[12pt, usenames]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage[margin=3.3cm]{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{graphicx} % support the \includegraphics command and options
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{tikz}
\usepackage[all]{xy}
\usepackage{mathtools}
\usepackage[hidelinks]{hyperref}
\usepackage{color}
\usepackage{float}
\usepackage[justification=centering]{caption}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{setspace}
\usepackage{eurosym}
\usepackage{listings} %% for R Code
\usepackage{natbib}
\usepackage{csquotes}
\usepackage{footnote}
\usepackage{amsmath}

%%% Listings options
\lstdefinelanguage{Renhanced}[]{R}{
  otherkeywords={!,!=,~,\$,*,\&,\%/\%,\%*\%,\%\%,<-,<<-, ::},
  morekeywords={},
  deletekeywords={hist, runif, plot, read.table, read, check, text, file, attributes, quote, missing, c, list, any, which, na, deparse, structure, install},
  alsoletter={.\%},%
  alsoother={:_\$}}

 \lstset{
  language=Renhanced,                     % the language of the code
  basicstyle=\small\ttfamily, % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{Blue},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it is 1, each line will be numbered
  numbersep=10pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=false,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  keywordstyle=\color{RoyalBlue},      % keyword style
  commentstyle=\color{YellowGreen},   % comment style
  stringstyle=\color{ForestGreen}      % string literal style
}

%%% BibTex Style
\setcitestyle{authoryear, open = { ( }, close = { ) }}

% Equation numbering
\numberwithin{equation}{section}

\renewcommand{\lstlistingname}{Code-Chunk}

%%% New commands
\newcommand{\li}{\lstinline}

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

\usepackage{setspace}
\onehalfspacing

%%% END Article customizations

%%% The "real" document content comes below...

\begin{document}
\newgeometry{margin=2.5cm}
\begin{titlepage}
\thispagestyle{empty}
\newcommand{\HRule}{\rule{\linewidth}{0.6mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{Georg-August Universität Göttingen}\\[1.5cm] % Name of your university/college

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
\begin{spacing}{1.5}
{ \LARGE \bfseries bamlss.vis: An R Package to Interactively Analyze and Visualize Bayesian Additive Models for Location, Scale and Shape (bamlss) Using the Shiny Framework}\\% Title of your document
\end{spacing}
\HRule \\[1.5cm]

\large{20 week Master thesis as part of the\\ Master of Science (M.Sc.) course ``Applied Statistics" \\ at the University of Göttingen \\[2cm]} % Major heading such as course name

%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.35\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
Stanislaus \textsc{Stadlmann},\\
Student ID: 21144637
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.45\textwidth}
\begin{flushright} \large
\emph{Supervisors} \\
Prof. Dr. Thomas \textsc{Kneib}\\
Dr. Nadja \textsc{Klein} \\
\end{flushright}
\end{minipage}\\[3cm]

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large Submitted on \today \\ by Stanislaus Stadlmann, \\ born in Vienna, Austria}\\[2.5cm]


%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

\includegraphics[scale = 0.7]{images/09_logo.jpg}\\[1cm]

%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace
\end{titlepage}
\restoregeometry
\clearpage

% TOC
\tableofcontents

\pagenumbering{Roman}
\clearpage

% List of...
\listoffigures
\listoftables
\clearpage

\pagenumbering{arabic}

\section{Introduction}
\label{introduction}
Since the commercialization of the personal computer and the smartphone about two decades later the overwhelming majority of modern life in developing nations has greatly been revolutionized. To name a few advancements, the period stretching from the late 20th century until today has seen changes in the way modern human beings communicate, listen to music, work and are entertained. The common denominator of these changes is the switch from analogue to digital processes, which saw the creation of entire industries, such as Digital Image Processing. The digital revolution also started a significant growth in the number of data collection possibilities and -techniques, with the newest breakthrough, the Internet of Things (IoT), being right around the corner~\citep{iotblog}. \par
The exponential increase in available datapoints, paired with dramatic improvements in computing power, gave rise to numerous advancements in statistical sciences. Many computation-heavy models were able to be applied on a broader basis and new methods, such as Neural Nets or Generalized Additive Models could finally be realistically used~\citep{econblog}. With the increase in number of new methods and improvements in data availability, the recent past also saw a significant rise in employed statisticians. In the United States alone, the number of jobs classified as statisticians has increased by more than 120\% in the years from 1997 to 2016~\citep{depstat}. \par
One of the new fields that has emerged is distributional regression, where not only the mean, but each parameter of a response distribution can be modeled using a set of predictors~\citep{klein2015}. Notable frameworks called Generalized Additive Models for Location, Scale and Shape (gamlss) and Bayesian Additive Models for Location, Scale and Shape (bamlss) were invented by~\citet{gamlss2001} in the form of a frequentist perspective and~\citet{bamlss2017} with a Bayesian approach, respectively. \par
Because methods have become increasingly more complex and capable over the years, it is important to make them accessible and understandable to the growing number of statistical users. In the case of distributional regression models, the interpretation of covariate effects on response moments and the expected conditional response distribution is harder than with traditional methods such as Ordinary Least Squares or Generalized Linear Models, since the moments of a distribution do not directly equate the modeled parameters, but are rather a combination of them with a varying degree of complexity. \par
This thesis will introduce a framework for the visualisation of distributional regression models fitted using the \textbf{bamlss} R package~\citep{bamlss2017} as well as display an implementation as an R extension titled \textbf{bamlss.vis}. The goal of this framework is the ability to:
\begin{itemize}
  \item See and compare the expected distribution for chosen sets of covariates and
  \item View the direct relationship between moments of the response distribution and a chosen explanatory variable, given a set of covariates.
\end{itemize}
Additionally, the user can obtain the code which created the graphs to potentially reproduce them later. The implementation will be done using the statistical software R~\citep{rsoftware} in the form of a Shiny application~\citep{shiny}. \par
% This thesis will be structured as follows...
% Vllt einen beispielgraphen zeigen?  problem vllt noch nicht ganz klar
\section{Motivating Bayesian Additive Models for Location, Scale and Shape}
\label{bamlss}
Bayesian Additive Models for Location, Scale and Shape (bamlss) are a form of Bayesian regression models in which every parameter of a parametric distribution with $K$ parameters is related to a set of additive predictors. The distribution does not have to follow the exponential family, which extends the distributions available for modeling beyond the ones used in Generalized Linear Models (GLM). In similar fashion to Generalized Additive Models~\citep[GAM,][]{hastie1990generalized}, the additive predictors can assume different shapes, including non-linear, fixed, random and spatial effects~\citep{bamlss2017}. \par
%In the ability to additively model multiple parameters of one distribution, bamlss bear many similarities with Generalized Additive Models for location, scale and shape~\citep[GAMLSS,][]{gamlss2001}. Disparities lie in the estimation of model parameters, where bamlss utilize Markov Chain Monte Carlo (MCMC) simulations which provide credible intervals in situations where asymptotic maximum likelihood confidence intervals often fail, as well as bamlss' ability to model multivariate parametric distributions~\citep{bamlss2017}. \par
To give a sufficient depiction of this model class, this section will start with explaining Additive Models and then gradually generalize the broader frameworks to finally arrive at bamlss. Furthermore, a brief overview of the different estimation techniques for the covered model frameworks will be given.\par

\subsection{Additive Models}
\label{AM}
Bamlss can be seen as a generalization of Structured Additive Regression, which are in turn a generalization of Additive Models. Additive Models, first proposed by~\citet{friedman1981projection} represent a model type in which a dependent variable $y$ is related to a set of non-parametric predictors in an additive way. Assuming conditional independence of $y_1, \ldots, y_n$ given the explanatory variables $\textbf{z}_1, \ldots, \textbf{z}_K$, we obtain the following model equation:
\begin{equation}
  \label{addmodel1}
  y_i = f_1(z_{i1}) + f_2(z_{i2}) + \ldots + f_k(z_{ik}) + \epsilon_i
\end{equation}
where $f_j(\cdot)$ depict unspecified non-parametric functions of covariate $z_j$, which can include smoothing splines or local regression approaches. This makes additive models more flexible compared to standard linear regression, while still being more interpretable than non-additive models~\citep{buja1989linear}. \par
\citet{fahrmeir2013regression} suggest that an Additive Model can also include parametric components. Given covariates $\textbf{x}_1, \ldots, \textbf{x}_Q$, we can extend \eqref{addmodel1} to a semiparametric regression model with the following specification:
\begin{equation}
  \label{addmodel2}
  y_i = \sum\limits_{j = 1}^K f_j(z_{ij}) + \underbrace{\sum\limits_{l = 1}^Q \beta_l x_{il}}_{\beta_0 + \beta_1 x_{i1} + \ldots + \beta_Q x_{iQ}} + \epsilon_i
\end{equation}
Eq. \eqref{addmodel2} combines non-parametric and parametric components. Because the model would otherwise not be identified, functions $f_j(\cdot)$ now have to be centered around zero, such that
\begin{equation*}
  \sum\limits_{i = 1}^n f_1(x_{i1}) = \ldots = \sum\limits_{i = 1}^n f_K(x_{iK}) = 0
\end{equation*}
holds. The functions $f_j(\cdot)$ are approximated using basis functions in the following scheme:
\begin{equation*}
  f_j(z_j) = \sum\limits_{m = 1}^{d_j} \textbf{B}_m(z_j) \gamma_{jm}
\end{equation*}
This allows to write the Additive Model in a matrix form, indifferent of the chosen basis:
\begin{equation}
  \label{addmatform}
  \textbf{y} = \sum\limits_{j = 1}^K \mathbf{Z}_j \boldsymbol{\gamma}_j + \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\epsilon}
\end{equation}
Here, the design matrices $\mathbf{Z}_1, \ldots, \mathbf{Z}_K$ represent the basis functions assessed at different covariates. $\mathbf{X}$ is constructed in equivalence to the standard linear regression model. Assumptions about the error term of a semiparametric Additive Model are also similar to the classic linear model, where $\epsilon_i$ are identically and independently (i.i.d) normally distributed with $E(\epsilon_i) = 0$ and $Var(\epsilon_i) = \sigma^2$. These properties are then also valid for the response variable, so that $y_i \overset{i.i.d.}{\sim} N(\hat{y}, \sigma^2_y)$ \citep[chap. 9.1]{fahrmeir2013regression}.

\subsection{Structured Additive Regression Models}
\label{STAR}
The nonparametric components in additive models open the possibility for more flexible relationships between the dependent variable and single explanatory variables, which standard linear regression methods might not capture correctly. However, sometimes the area of model application requires even more flexibility, e.g. by including spatial covariates, fixed/random effects or interaction terms. These specific types of effects extend the Additive Model to a Structured Additive Regression Model \citep[STAR]{fahrmeir2003}. This chapter will briefly describe its different components. \par

\subsubsection{Spatial Effects}
Similarly to Section \ref{AM}, observations $(y_i, \mathbf{z}_i, \mathbf{x}_i)$ are given, where $\mathbf{z}_i$ and $\mathbf{x}_i$ represent vectors of covariate values for the $i$th observation. Additionally, a geographic location index $s$ is known with observations $s_i$, which can be either discrete (e.g. region or country) as well as continuous (e.g. longitude/latitude). Extending the semiparametric Additive Model as specified in \eqref{addmodel2}, a geospatial effect is now added:
\begin{equation}
  \label{geoaddmodel}
  \begin{split}
    y_i & =  \sum\limits_{j = 1}^K f_j(z_{ij}) + \sum\limits_{l = 1}^Q \beta_l x_{il} + f_{geo}(s_i) + \epsilon_i\\
    & = \kappa^{add} + f_{geo}(s_i) +\epsilon_i
  \end{split}
\end{equation}
$\kappa^{add}$ includes the non-spatial effects from \eqref{addmodel2}. The spatial effect, $f_{geo}(\cdot)$, is often viewed as a proxy for unknown covariates, such as altitude or climate data. If the geographic location index $s$ is tracked using discrete values, $f_{geo}(\cdot)$ could represent a Markov random field. For continuous values, smoothing techniques such as Kriging \citep{matheron1963principles} or a multivariate tensor product spline are available. In both the discrete and the continuous case, the vector of geoadditive components $\boldsymbol{f}_{geo}$ can be written as
\begin{equation*}
  \boldsymbol{f}_{geo} = \mathbf{Z}_{geo} \boldsymbol{\gamma}_{geo}
\end{equation*}
so that it can be incorporated into the geoadditive model in matrix notation in the following way
\begin{equation}
  \label{geoaddmatform}
  \textbf{y} = \sum\limits_{j = 1}^K \mathbf{Z}_j \boldsymbol{\gamma}_j + \mathbf{X} \boldsymbol{\beta} + \mathbf{Z}_{geo} \boldsymbol{\gamma}_{geo} + \boldsymbol{\epsilon}
\end{equation}
which bears similarities to the basis function approach in \eqref{addmatform} \citep[chap. 9.2]{fahrmeir2013regression}. \par

\subsubsection{Interaction Terms}
The regression equation \eqref{addmodel2} of Additive Models included main nonparametric and parametric effects, but no interactions between covariates. When incorporating interaction effects, one has to differentiate between an interaction between a continuous and a categorical variable, as well as one where two continuous variables share a common effect \citep[chap. 9.3]{fahrmeir2013regression}. \par
To illustrate the first case, it is assumed that $z_1$ and $x_1$ are continuous and binary ($x_i \in (0, 1)$) covariates, respectively. Then, the interaction term $f_{z_1|x_1}(z_1) \cdot x_1$ can be included in the Additive Model from \eqref{addmodel2} in the following way:
\begin{equation*}
  \label{interaddmodel}
  y_i =  \sum\limits_{j = 1}^K f_j(z_{ij}) + \sum\limits_{l = 1}^Q \beta_l x_{il} + \underbrace{f_{z_1|x_1}(z_{i1}) x_{i1}}_{\substack{0 \qquad \: \: \: \: \: \: \: \: \text{if} \:  x_{i1} = 0 \\[0.1cm] f_{z_1|x_1}(z_{i1}) \: \text{if} \: x_{i1} = 1}} + \epsilon_i
\end{equation*}
If $x_1 = 0$, the non-linear effects of $z_1$ are now
\begin{equation*}
  \begin{split}
    f_1(z_1) \quad & \text{if} \, \, x_1 = 0 \\
    f_1(z_1) + f_{z_1|x_1}(z_1) + \beta_1 \quad & \text{if} \, \, x_1 = 1
  \end{split}
\end{equation*}
This framework can also incorporate spatially covarying terms, where the interaction term $f_{geo|x_1}(s)$ represents an interaction between the location variable $s$ and a categorical variable $x_1$ \citep{fahrmeir2013regression}. \par
Using a Basis function approach, the vector of interaction effects
\begin{equation*}
  \boldsymbol{f}_{int} = (f_{z_1|x_1}(z_{11}) x_{11}, \ldots, f_{z_1|x_1}(z_{n1}) x_{n1})
\end{equation*}
 can also be described in matrix notation to extend \eqref{addmatform} in the following way:
\begin{equation*}
  \textbf{y} = \sum\limits_{j = 1}^K \mathbf{Z}_j \boldsymbol{\gamma}_j + \mathbf{X} \boldsymbol{\beta} + \mathbf{Z}_{int} \boldsymbol{\gamma}_{int} + \boldsymbol{\epsilon}
\end{equation*}
Here, the design matrix $\boldsymbol{Z}_{int}$ represents the Basis function values multiplied with $x_1$ observations \citep[chap. 9.3]{fahrmeir2013regression}. \par
The possibility of interactions between two continuous covariates is also given. In this case, the interaction between $z_1$ and $z_2$ is modeled using a two-dimensional nonparametric function $f_{z_1|z_2}(z_1, z_2)$. Common two-dimensional functions include bi-variate smooth splines and Kriging techniques. When only the two-dimensional functions without main effects ($f_1(z_1)$, $f_2(z_2)$) should be included, the model equation assumes the following form:
\begin{equation}
  y_i =  f_{z_1|z_2}(z_{i1}, z_{i2}) + f_3(z_{i3}) + \ldots + f_K(z_{iK}) + \sum\limits_{l = 1}^Q \beta_l x_{il} + \epsilon_i
\end{equation}
For reasons of identifiability, $f_{z_1|z_2}(z_1, z_2)$ also needs to be centered around zero. \citet[chap. 9.3.2]{fahrmeir2013regression} warn that for estimation of models with two-dimensional surfaces a high sample size with combinations of $z_1$ and $z_2$ is required. In cases where this requirement is not fulfilled, a simple main effects model as in \eqref{addmodel2} is preferred. \par
It is also possible to model the interaction effect of $z_1$ and $z_2$ using the two-dimensional surface $f_{z_1|z_2}(z_1, z_2)$ while still including the main effects. In this scenario, the model is specified as follows:
\begin{equation}
y_i =  f_{z_1|z_2}(z_{i1}, z_{i2}) + f_1(z_{i1}) + f_2(z_{i2}) + \sum\limits_{j = 3}^K f_j(z_{ij}) + \sum\limits_{l = 1}^Q \beta_l x_{il} + \epsilon_i
\end{equation}
The identifiability problem in this model is more complex than before. To solve it, \citet[chap. 9.3]{fahrmeir2013regression} state that not only all included functions have to be centered around zero, but also \enquote{all slices of the interaction $f_{z_1|z_2}(z_1, z_2)$, i.e. all one-dimensional smooths with fixed value of $z_1$ or $z_2$}.
Using the basis function approach, the matrix representation of the model can be obtained:
\begin{equation}
  \textbf{y} = \sum\limits_{j = 1}^K \mathbf{Z}_j \boldsymbol{\gamma}_j + \mathbf{X} \boldsymbol{\beta} + \mathbf{Z}_{z_1|z_2} \boldsymbol{\gamma}_{z_1|z_2} + \boldsymbol{\epsilon}
\end{equation}
with interaction term design matrix $\mathbf{Z}_{z_1|z_2}$ \citep[chap. 9.3]{fahrmeir2013regression}. \par

\subsubsection{Random Effects}
When dealing with repeated measures or other longitudinal datasets it is often necessary to model cluster-specific similarities using Random Effects \citep{laird1982random}. Additive Models can also be extended with Random Effects to arrive at so called Additive Mixed Models. Assuming a longitudinal data structure with subjects $j = 1, ..., n_i$ in clusters $i = 1, ..., m$ and covariates $\textbf{x}_k$, a parametric random coefficient model possesses the following structure:
\begin{equation*}
  y_{ij} = (\beta_0 + \nu_{0i}) + (\beta_1 + \nu_{1i}) x_{ij1} + \ldots + (\beta_Q + \nu_{Qi}) x_{ijQ} + \epsilon_i
\end{equation*}
The \enquote{random} coefficients $\nu_{0i}$ (intercept) and $\nu_{1i}, \ldots, \nu_{Qi}$ (slopes) represent the cluster-specific deviations from the main effects. To obtain Additive Mixed Models, the main effects are then replaced with nonparametric functions:
\begin{equation}
  y_{ij} = f_1(x_{ij1}) + \ldots + f_Q(x_{ijQ}) + \nu_{0i} + \nu_{1i} x_{ij1} + \ldots + \nu_{Qi} x_{ijQ} + \epsilon_i
\end{equation}
Like non-parametric main effects, Random Effects also have a matrix notation. In the case where every main effect is also modeled with cluster-specific effects, the matrix form of Additive Mixed Models is as follows:
\begin{equation*}
  \mathbf{y} = \sum\limits_{j = 1}^K \mathbf{Z}_j \boldsymbol{\gamma}_j + \mathbf{R}_0 \boldsymbol{\nu}_0 + \sum\limits_{j = 1}^K \mathbf{R}_j \boldsymbol{\nu}_j + \boldsymbol{\epsilon}
\end{equation*}
Here, $\boldsymbol{\nu}_0 = (\nu_{01}, \ldots, \nu_{0m})'$ and $\boldsymbol{\nu}_j = (\nu_{j1}, \ldots, \nu_{jm})'$ represent the Random Effects coefficients. A more in-depth look at the structure of the design matrices is given by \citet[chap. 9.4, p. 550]{fahrmeir2013regression} \par

\subsection{Generalized Structured Additive Regression Models}
Structured Additive Regression (STAR) models extend simple Additive Models with special model terms briefly introduced in the previous sections. These effects include:
\begin{itemize}
  \item Nonlinear effects of $z_1$
  \item Spatial effects of location index $s$
  \item Interactions between continuous covariate $z_1$ and a categorical variable $x_1$
  \item Nonlinear interactions between two continuous covariates $z1$, $z_2$
  \item Random Effects with intercept $\nu_0$ and slope $\nu_j$ deviations from main effects
\end{itemize}
All of the aforementioned model terms can be included in a STAR interchangeably, including simple linear predictors $\mathbf{x}' \boldsymbol{\beta}$ \citep[chap 9.5]{fahrmeir2013regression}. \par
STAR models provide very flexible ways of modeling the influence of explanatory variables on a given response variable $y_i$. Note that while the components can be nonparametric, the direct modeling of $y_i$ assumes that the response variable follows a Gaussian distribution. However, when dealing with e.g. binary or categorical responses, this assumption is violated. Then, a type of model specification is needed that directly upholds the dependent variables' support \citep[chap. 2]{olsson2002}. To solve this challenge, STAR models are merged with Generalized Linear Models to Generalized STAR models.\par
Generalized Linear Models (GLM), first coined by \citet{nelder1972}, introduce a framework where the expectation of response $y$ is related to a linear predictor $\eta = \textbf{x}'\boldsymbol{\beta}$ via a link function $\eta = g(E(y)) = g(\mu)$ or a response function $h = g^{-1}$ to arrive at the following model specification:
\begin{equation}
  \label{GLM}
  \begin{split}
    \mu_i & = h(\mathbf{x}_i' \boldsymbol{\beta}) \quad \text{or} \\
    g(\mu_i) &  = \mathbf{x}_i' \boldsymbol{\beta}
  \end{split}
\end{equation}
When modeling a binomially distributed response the probability parameter $\pi$, which has a support of $\pi \in [0, 1]$, is related to predictors $\textbf{x}' \boldsymbol{\beta}$. Using a logit link function, we obtain a Logistic Regression Model:
\begin{equation*}
  \begin{split}
    \eta_i & = \mathbf{x}'_i \boldsymbol{\beta} \\
    E(y_i) & = \pi_i = \frac{exp(\eta_i)}{1 + exp(\eta_i)}
  \end{split}
\end{equation*}
Here, the response function ensures the correct support of $\pi$ \citep[chap. 5]{fahrmeir2013regression}. Using a link function, the expectation of $y$ can be the first moment of many different continuous or discrete distributions, which includes the Poisson, Binomial and Gamma distribution. However, all possible distributions need to be part of the exponential family \citep{gamlss2005}. \par
Note in \eqref{GLM} that the effects of covariates $\textbf{x}_1, \ldots, \textbf{x}_K$ are modeled parametrically. Generalized Additive Models (GAM), as suggested by \citet{hastie1990generalized}, extend the class of Generalized Linear Models to allow for non-parametric effects. In particular, the linear predictor $\eta = \textbf{x}' \boldsymbol{\beta}$ is interchanged by smooth non-parametric functions $f_j(x_j)$. Given response variable $y$ and covariates $\mathbf{z}_1, \ldots, \mathbf{z}_K$, the following model specification is obtained:
\begin{equation}
  \label{GAM}
  \begin{split}
    \eta_i & = \sum\limits_{j = 1}^K f_j(x_{ij}) \\
    \mu_i & = E(y_i) = h(\eta_i)
  \end{split}
\end{equation}
Now, many different response distributions as well as flexible effects for explanatory variables are supported to create a highly flexible model framework. In \eqref{GAM}, only non-parametric effects are linked to $\eta_i$. However, given response $y$ and covariates $(\mathbf{x}_i, \mathbf{z}_i$), all specific effects of STAR models (spatial effects $f_{geo}(\cdot)$, interactions $f_{int}(\cdot)$, etc.) as well as parametric coefficients can be combined to form a Generalized Structured Additive Regression Model (Generalized STAR):
\begin{equation}
  \begin{split}
    \eta_i & = f_1(z_{i1}) + \ldots + f_K(z_{iK}) + \beta_0 + \beta_1 x_{i1} + \ldots + \beta_Q x_{iQ} \\
    \mu_i & = h(\eta_i)
  \end{split}
\end{equation}
In semiparametric Generalized STAR models, $f_j(\cdot)$ can have any of the structural forms described in Chapter \ref{STAR}. Modeled response variables also have to follow an exponential family distribution \citep[chap. 9.5]{fahrmeir2013regression}.

\subsection{Structured Additive Distributional Regression}
Generalized STAR models provide a framework to flexibly estimate the expected value of a previously specified distributional parameter. However, in many cases not only the first moment, but also higher-order moments are of special interest. In modeling income, for example, not only the expected income but also the shape of the overall distribution is important. A common measure for income inequality is the Gini coefficient, which can be calculated using the cumulative distribution function (cdf) \citep{lerman1984note}. \par

\subsubsection{GAMLSS}
First modeling approaches which go beyond the mean of a distribution were suggested by \citet{nelder1987} using parametric functions of explanatory covariates related to the dispersion parameter $\phi$ of en exponential family distribution. Building upon this approach, Generalized Additive Models for Location, Scale and Shape (gamlss) were introduced by \citet{gamlss2001}. Gamlss combine the flexibility of being able to model multiple distributions with parametric or nonparametric explanatory effects and extend them for multiple response distribution parameters such that not only the location, but also the scale and shape of a distribution can be modeled simultaneously. Furthermore, gamlss relax the assumption of $y$ following an exponential family distribution, which significantly increases the number of response modeling possibilities. \par
Assuming a dependent variable from a distribution with parameters $\theta_1, \ldots, \theta_{L}$ and observations $y_1, \ldots, y_n$, given covariates $\mathbf{z}_1, \ldots, \mathbf{z}_K$ and $\mathbf{x}_1, \ldots, \mathbf{x}_Q$, a gamlss can be described with the following model specification:
\begin{equation}
  \label{gamlss}
  g_l(\theta_{il}) = \eta_{il} = \mathbf{x}'_{il} \boldsymbol{\beta} + \sum\limits_{j = 1}^{K_l} f_{jl}(z_{ijl})
\end{equation}
In Equation \eqref{gamlss}, $g_l(\cdot)$ represents a known monotonic link function, which can be different for each parameter. $\textbf{x}'_{il}$ depicts the subset of $x$ variables used to model parameter $\theta_l$ in observation $i$, while $f_{jl}(z_{ijl})$ serves as a non-parametric effect of covariate $z_j$ on parameter $\theta_l$, taken from a subset of the $K$ $z$ variables, evaluated for the $i$th observation. The specific subset of covariates $z$ with nonparametric effects on parameter $\theta_k$ has a length of $K_l$ variables \citep{gamlss2007}. \par
As shown above, gamlss can utilize different combinations of parametric and non-parametric effects to model each distributional parameter. Equation \ref{gamlss} displays a case in which every parameter is modeled using a non-empty subset of variables $x$ and $z$. However, some parameters can also be set to a constant and not be dependent on covariates. For example, when assuming the Gaussian distribution for the dependent variable and connecting $\mu$ to parametric effects $\mathbf{x}_j$ using the identity link function ($g(\mu) = \mu$) and the variance parameter $\sigma^2$ to a constant, we arrive at a linear model specification \citep{gamlss2007}. \par

\subsubsection{BAMLSS}
As mentioned in the introduction of this thesis, not always do the modeled parameters directly equate the moments (location, scale and shape) of a distribution, but rather a combination of them. For this reason, approaches to simultaneously model the parameters of a distribution are often referred to as distributional regression, which includes gamlss. However, as seen in \eqref{gamlss}, gamlss in its normal form only incorporate main effect modeling. To further integrate structured additive terms, such as spatial effects, random effects and interaction terms \citep{brezger2006}, distributional regression is further extended to Structured Additive Distributional Regression \citep{klein2015}. \par
In \citeyear{klein2013}, \citeauthor{klein2013} introduced Bayesian Additive Distributional Regression, which is a model type extending gamlss to include structured additive predictors for modeling parameters of a specified distribution. It represents a fully Bayesian approach, in which coefficients are obtained by drawing samples from the approximate posterior effect distributions using using Markov Chain Monte Carlo (MCMC) simulations.  \par
% Since then, there have been many papers published with applications of Bayesian Additive Distributional Regression. papers raussuchen und zitieren
An implementation of Bayesian Additive Distributional Regression, called Bayesian Additive Models for Location, Scale and Shape (bamlss) was since created by \citet{bamlss2017}. As the authors point out, the name bears resemblance to gamlss, because of many similarities in its modeling approach. However, extensions of bamlss over gamlss are manifold. First, parallel to the proposed framework of \citet{klein2013}, MCMC simulations are utilized for estimation of coefficients. This is done in contrast to gamlss, where predictor coefficient estimates are retrieved via penalised likelihood maximisation techniques. Advantages of using MCMC simulations over likelihood-based approaches include the sample-based inference, which yields more reliable confidence intervals than the intervals of gamlss estimates based on asymptotic properties. Second, bamlss offer more flexibility of specifying covariate effects with the support of structured additive predictors, like spatial effects or two-dimensional splines. Third, bamlss also support multivariate response distributions, which enhances gamlss' univariate response framework. Furthermore, the implementation of bamlss is designed in a way that allows for the usage of external estimation algorithms and software packages like JAGS or BayesX. \par
The model specification of bamlss is similar to the gamlss class. The parameters $\theta_1, \ldots, \theta_L$ of a parametric distribution $\mathbf{y}$ with observations $y_1, \ldots, y_n$ are linked to structured additive predictors using monotonic and twice-differentiable link functions $g_l(\theta_l)$ (note that the paper uses $h_l(\theta_l)$). Based on covariates $\mathbf{x}_1, \ldots, \mathbf{x}_Q$, the following model equation can be obtained:
\begin{equation}
g_l(\theta_l) = f_{1l}(\mathbf{x}_{1l} ; \boldsymbol{\beta}_{1l}) + \ldots + f_{Q_{l}l}(\mathbf{x}_{Q_{l}l} ; \boldsymbol{\beta}_{Q_{l}l})
\end{equation}
Here, $f_{j_{l}l}(\cdot)$ represent unspecified functions that can attain any structured additive predictor forms, including nonparametric effects. It is also possible to describe the effects in vector form:
\begin{equation*}
  \boldsymbol{f}_{jl} =
  \begin{bmatrix}
    f_{jl}(\mathbf{x}_1 ; \boldsymbol{\beta}_{jl}) & \\
    \vdots & \\
    f_{jl}(\mathbf{x}_n ; \boldsymbol{\beta}_{jl}) &
  \end{bmatrix} =
  f_{jl}(\mathbf{X}_{jl} ; \boldsymbol{\beta}_{jl})
\end{equation*}
with $\mathbf{X}_{jl}$ ($n \times m_{jl}$) specifying the design matrix for effect $f_{jl}(\cdot)$ so that they integrate themselves into the following model equation
\begin{equation}
  g_{l}(\boldsymbol{\theta}_{l}) = \boldsymbol{\eta}_l = \boldsymbol{f}_{1k} + \ldots + \boldsymbol{f}_{J_{l}l}
\end{equation}
where $\boldsymbol{f}_{jl}$ represents the $j$th effect of $\mathbf{x}_{jl}$ (subvector of $\mathbf{x}$) on parameter $\theta_l$. Similar to Chapters \ref{AM} and \ref{STAR}, effects in bamlss can also be derived through a basis function approach, such that it can be written as $\boldsymbol{f}_{jl} = \mathbf{X}_{jl} \boldsymbol{\beta}_{jl}$. The structure of the design matrix depends on the types of covariates and prior assumptions about $f_{jl}(\cdot)$ \citep{bamlss2017}.
As mentioned earlier in this chapter, bamlss offer very flexible ways of specifying covariate effects. Breaking through the framework of basis function approaches, bamlss also allow covariate functions $f_{jl}(\cdot)$ which are nonlinear in its parameters $\boldsymbol{\beta}_{jl}$. An example of this is the Gompertz growth curve
\begin{equation*}
  \boldsymbol{f}_{jl} = \beta_1 \cdot \text{exp}(-\text{exp}(\beta_2 + \mathbf{X}_{jl} \beta_3))
\end{equation*}
with nonlinear parameters $\boldsymbol{\beta}_{jl}$\citep{bamlss2017}.
% Sunday5Nov: replace the parametric effects everywhere such that it includes an intercept man!
\subsection{Estimation}
\label{estimation}
% In this section we will discuss different estimation techniques for the models introduced in this chapter
% AM: backfitting
% STAR: pen least squares, mixed model rep, fully bayesian inference, boosting as suggested in fahrmeir2013regression, page 561

\section{bamlss.vis}
\label{bamlss.vis}
The previous Sections \ref{AM} to \ref{estimation} gave a description of Bayesian Additive Models for Location, Scale and Shape (bamlss) and the underlying sub-models on which they are based. This section will introduce a framework to interactively visualize covariate effects and distributional predictions of fitted bamlss models and feature its implementation as an R package. Because of the visual component, the tool will be called \textbf{bamlss.vis}. A small case-study based on wages of male workers in the Mid-Atlantic region will be presented to feature most of bamlss.vis' abilities. \par

\subsection{Motivation}
As discussed in previous sections, distributional regression is concerned with modeling the parameters of a known parametric distribution. After estimation of the model, the user obtains coefficients which measure the influence of an explanatory variable on $\eta_l$, which represents the transformed parameter $\theta_l$. However, in most cases the user is not interested in specific distributional parameters but more in the moments, which often do not directly equate the parameters but are rather a combination of them. \par
This problem can be well illustrated using the censored normal distribution. Assume a normally distributed variable, $y \sim N(\mu, \sigma^2)$. Then, the probability density function (pdf) of a left-censored normal distribution $y^*$ with cut-off point $a = 0$ can be obtained by
\begin{equation*}
  f(y^* = x) =
  \begin{cases}
    f(y = x) & x > 0 \\
    F(y = \frac{-\mu}{\sigma}) & x \leq 0
  \end{cases}
\end{equation*}
where $f(y)$ and $F(y)$ are the probability density functions (pdf) and the cumulative distribution function cdf() of normally distributed variable $y$, respectively. It is visible in the above equation that the censored normal distribution is both discrete and continuous. While $y^*$ shares the density with $y$ above the cut-off point, the full remaining density in the censored normal distribution is assigned to the cut-off point $a$. Figure \ref{cnorm_plot} shows a sample left-censored normal distribution $y^*$ created from $y \sim N(0, 1)$ with $a = 0$ \citep{greene2012}. \par
\begin{figure}
  \begin{centering}
    \includegraphics{images/06_cnorm_plot.pdf}
  \caption{Probability Density Function of a left-censored normal distribution with the expected value drawn as a blue line.}
  \label{cnorm_plot}
  \end{centering}
\end{figure}
As visible in Figure \ref{cnorm_plot}, the moments of the standard normal distribution do not carry over to the censored normal distribution. In fact, while $E(y) = 0$, the expected value of $y^*$ is $E(y^*) \approx 0.399$. To be exact, the censored normal distributions first two moments with cut-off $a = 0$ can be calculated as follows:
\begin{equation}
  \label{cnorm_moments}
  \begin{split}
    E(y^*) & =  (1 - \alpha) \cdot (\mu + \sigma\beta) \quad \text{and}\\
    Var(y^*) & = \sigma^2 (1 - \alpha) \cdot [(1 - \gamma) + (\frac{-\mu}{\sigma} - \beta)^2 \cdot \alpha] \quad \\[0.5cm]
    \text{while:} \quad \alpha & = \Phi(\frac{-\mu}{\sigma}) \\
    \beta & = \frac{\phi(\frac{\mu}{\sigma})}{1 - \alpha} \\
    \gamma &= \beta^2 - \beta \cdot (\frac{-\mu}{\sigma})
  \end{split}
\end{equation}
where $\phi(\cdot)$ and $\Phi(\cdot)$ are the probability density function (pdf) and cumulative distribution function (cdf) of the standard normal distribution and $\mu$ and $\sigma^2$ are the parameters of $y$, respectively \citep{greene2012}. Equation \eqref{cnorm_moments} shows that both the expected value and the variance of $y^*$ are computed by a combination of the parameters of the original variable $y$, $\mu$ and $\sigma^2$, and are not equal. Thus, an explanatory variable that has a positive effect on $\mu$ has both an impact on $E(y^*)$ and $Var(y^*)$. Therefore, coefficients for measuring covariate influences on those parameters are not directly translateable to the moments of the modeled distribution and might even have critically different estimates. \par
Furthermore, even in cases where the desired moments directly equate the modeled parameters (e.g. in gaussian or poisson-distributed responses), different link functions for their transformation $g_l(\theta_l)$ and possibly highly complex nonparametric effects of explanatory variables can lead to coefficient estimates that are hard to interpret. In this case, a visual comparison of predicted distributions would be helpful. \par
To tackle both of the aforementioned interpreting problems with fitted bamlss models, this thesis will introduce a framework with two main objectives:
\begin{itemize}
  \item Visually compare the predicted distributions (pdf or cdf) based on interactively selected covariates
  \item View the changes of distribution moments over the whole range of a selected variable, based on chosen explanatory covariates.
\end{itemize}
Using \textbf{bamlss.vis}, one can then observe the influence of a covariate on the distribution by 1. its cdf or pdf and 2. its moments. \par

\subsection{Case-Study}
While testing of \textbf{bamlss.vis}' main functions relies on artifical data for each supported distribution in order to prove correct behaviour, presenting the apps' abilities is best done with a dataset of real observations. The objective for a suitable dataset was that its response variable and explanatory variables are easy to understand for people without a specific scientific background. The chosen dataset, \enquote{Wage} from the ISLR R package \citep{ISLR} perfectly encompasses these requirements. %blabla it is from blabla and has following variables

\subsection{Structure of App}

% because so many different model flexibilities we will base the add-in on bamlss
% Hier muss auf jeden Fall ein Beispiel rein wo die parameter nicht gleich die momente sind um das zu zeigen

\section{Conclusion}
% Outlook: More distributions with gamlss.dist package?
% User-specific parameter combinations?

\clearpage

\section*{Appendix}

\clearpage

\bibliography{bibliography}{}
\bibliographystyle{plainnat}

\end{document}
